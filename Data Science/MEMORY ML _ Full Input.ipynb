{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilities\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ML\n",
    "#import sklearn\n",
    "#sklearn.__version__# use this when reopening previously saved ML models\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, RandomizedSearchCV, train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "    #pprint allows us to see current hyperparameter values of our model \n",
    "from pprint import pprint\n",
    "# import data\n",
    "memData = pd.read_csv(\"vminCkbNEW.csv\")\n",
    "\n",
    "#for i in memData.columns:\n",
    "#    print(memData[i].unique())\n",
    "\n",
    "# drop file index for now, maybe used later to include data from the wafer\n",
    "memData.drop([\"File Index\", \"Test Number\", \"??\", \"VDDPE (Range)\", \"VDDCE (Range)\", \"DVDD (Range)\", \"Period (Range)\", \"Value\", \"Number of Failed Pins\", \"Failed Pins\"], axis = 1, inplace = True)\n",
    "memData.dropna(subset=['Shmoo Value'], inplace=True)\n",
    "memData['EMA#1'] = memData['EMA#1'].map(lambda x: x.lstrip('A'))\n",
    "memData['EMA#2'] = memData['EMA#2'].map(lambda x: x.lstrip('B'))\n",
    "memData['EMAW'] = memData['EMAW'].map(lambda x: x.lstrip('A'))\n",
    "memData['EMAS'] = memData['EMAS'].map(lambda x: x.lstrip('A'))\n",
    "memData[\"Shmoo Value\"] = memData[\"Shmoo Value\"].astype('float')\n",
    "columns = ['EMA#1', 'EMA#2', 'EMAW', 'EMAS', 'EMAP', 'WABL', 'WABLM', 'RAWL', 'RAWLM', 'KEN']\n",
    "for c in columns:\n",
    "    memData[c] = memData[c].astype('int')\n",
    "memData['Chip Temp'] = pd.to_numeric(memData['Chip Temp'], errors='coerce').fillna(-40.0).astype(float)\n",
    "memData['Chip Temp'] = memData['Chip Temp'].map(lambda x: x/150.0)\n",
    "memData['Architecture'] = memData['Architecture'].map(lambda x: re.search('[A-Za-z0-9]+', x).group(0))\n",
    "memData = pd.get_dummies(memData, columns=[\"Architecture\", \"Chip Type\", \"A/S\", \"EMA#1\", \"EMA#2\", \"EMAW\", \"EMAS\", \"EMAP\", \"WABL\", \"WABLM\", \"RAWL\", \"RAWLM\", \"KEN\"])\n",
    "memData.drop([\"Arch. Type\", \"WABL_99\", \"WABLM_99\", \"RAWLM_99\", \"RAWL_99\", \"KEN_99\", \"EMA#2_99\", \"EMAS_99\", \"EMAP_99\", \"EMAW_99\"], axis = 1, inplace = True)\n",
    "memData.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = 'sc7p5mcpp96p_sfk_lvt_c16'\n",
    "re.split('_', string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training and testing sets\n",
    "X = memData.copy()\n",
    "X = shuffle(X)\n",
    "y = X[\"Shmoo Value\"]\n",
    "X.drop([\"Shmoo Value\"], axis = 1, inplace = True)\n",
    "\n",
    "X_train = X[:144931]\n",
    "y_train = y[:144931]\n",
    "X_test = X[-16103:]\n",
    "y_test = y[-16103:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomized search for hyperparameter optimization\n",
    "rf = RandomForestRegressor()\n",
    "pprint(rf.get_params())\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "pprint(random_grid)\n",
    "\n",
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)\n",
    "rf_random.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#comparison of base model and randomsearch result\n",
    "base_model = RandomForestRegressor(random_state = 42)\n",
    "base_model.fit(X_train, y_train)\n",
    "y_predicted_base = base_model.predict(X_test)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "print(mean_squared_error(y_test, y_predicted_base))\n",
    "\n",
    "best_random = rf_random.best_estimator_\n",
    "y_predicted_random = best_random.predict(X_test)\n",
    "print(mean_squared_error(y_test, y_predicted_random))\n",
    "\n",
    "for i in range(5):\n",
    "    print(\"For the base model:\")\n",
    "    print(\"The test label is \" + str(y_test.iloc[i]) + \" and the predicted value is \" + str(y_predicted_base[i]))\n",
    "    print(\"For the randomized search optimal model:\")\n",
    "    print(\"The test label is still \" + str(y_test.iloc[i]) + \" and the predicted value is \" + str(y_predicted_random[i]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# this is just some bs, forget about it\n",
    "\n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [None],\n",
    "    'max_features': ['auto'],\n",
    "    'min_samples_leaf': [3, 4],\n",
    "    'min_samples_split': [9,10],\n",
    "    'n_estimators': [1600]\n",
    "}\n",
    "\n",
    "rfGrid = RandomForestRegressor()\n",
    "grid_search = GridSearchCV(estimator = rfGrid, param_grid = param_grid, \n",
    "                          cv = 3, verbose = 2)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "grid_search.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(feature_importances)\n",
    "ax = feature_importances.plot.bar(rot=65)\n",
    "plt.show()\n",
    "plt.scatter(y_test, y_predicted_grid,  color='green', alpha=0.03)\n",
    "plt.xlim([0.2,0.7])\n",
    "plt.ylim([0.2,0.7])\n",
    "plt.plot([0.2,0.7],[0.2,0.7], color='black')\n",
    "plt.xlabel(\"Test Vmin\")\n",
    "plt.ylabel(\"Predicted Vmin\")\n",
    "plt.title(\"Memory Cell Vmin Prediction Error\")\n",
    "plt.show()\n",
    "\n",
    "print(mean_absolute_error(y_test, y_predicted_grid))\n",
    "print(mean_absolute_error(y_test, y_predicted_grid)/y_test.mean())\n",
    "\n",
    "from joblib import dump, load\n",
    "dump(best_grid, 'RFVminMem.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Utilities\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ML\n",
    "#import sklearn\n",
    "#sklearn.__version__# use this when reopening previously saved ML models\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, RandomizedSearchCV, train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "    #pprint allows us to see current hyperparameter values of our model \n",
    "from pprint import pprint\n",
    "\n",
    "a = pd.read_csv(\"vminCkbNEW.csv\")\n",
    "a.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#a['Architecture'] = a['Architecture'].map(lambda x: re.search('[A-Za-z0-9]+', x).group(0))\n",
    "a['Architecture'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
